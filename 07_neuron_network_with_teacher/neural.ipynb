{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e51b24f",
   "metadata": {},
   "source": [
    "# Neuronové sítě - učení s učitelem - klasifikace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0825548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models, datasets, applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d05c36",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "---\n",
    "\n",
    "seznam datasetů v TensorFlow https://www.tensorflow.org/datasets/catalog/overview#all_datasets\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load and preprocess data\n",
    "(training_images, training_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "training_images = training_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = 10\n",
    "training_labels_one_hot = tf.keras.utils.to_categorical(training_labels, num_classes)\n",
    "test_labels_one_hot = tf.keras.utils.to_categorical(test_labels, num_classes)\n",
    "\n",
    "class_names = ['Airplane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
    "\n",
    "# Visualize some examples\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(training_images[i])\n",
    "    plt.xlabel(class_names[training_labels[i][0]])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "3f9a125e2bae71b0"
  },
  {
   "cell_type": "markdown",
   "id": "c1f5b493",
   "metadata": {},
   "source": [
    "## Neuronová síť - stavba\n",
    "---\n",
    "různé typy vrstev v tf.keras.layers - (https://www.tensorflow.org/api_docs/python/tf/keras/layers)\n",
    "\n",
    "různé typy aktivačních funkcí - (https://www.tensorflow.org/api_docs/python/tf/keras/activations)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define the distillation loss function\n",
    "def knowledge_distillation_loss(alpha=0.1, temperature=5.0):\n",
    "    def loss_function(y_true, y_pred):\n",
    "        # Extract the true labels and soft targets from y_true\n",
    "        # First 10 values are true labels, next 10 are teacher's soft targets\n",
    "        true_labels = y_true[:, :num_classes]\n",
    "        soft_targets = y_true[:, num_classes:]\n",
    "\n",
    "        # Standard categorical crossentropy for true labels\n",
    "        ce_loss = tf.keras.losses.categorical_crossentropy(true_labels, y_pred)\n",
    "\n",
    "        # KL divergence for soft targets (with temperature scaling)\n",
    "        kd_loss = tf.keras.losses.kullback_leibler_divergence(\n",
    "            tf.nn.softmax(soft_targets / temperature),\n",
    "            tf.nn.softmax(y_pred / temperature)\n",
    "        ) * (temperature ** 2)\n",
    "\n",
    "        # Combined loss\n",
    "        return (1 - alpha) * ce_loss + alpha * kd_loss\n",
    "\n",
    "    return loss_function\n",
    "\n",
    "# ---------- TEACHER MODEL (ResNet50) ---------- #\n",
    "def create_teacher_model():\n",
    "    # Using a pre-trained model with higher capacity\n",
    "    # For CIFAR-10 (32x32 images), we'll use a smaller model\n",
    "    base_model = applications.ResNet50(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(32, 32, 3)\n",
    "    )\n",
    "\n",
    "    # Freeze the base model\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# ---------- STUDENT MODEL (Your CNN) ---------- #\n",
    "def create_student_model():\n",
    "    model = models.Sequential([\n",
    "        # Input layer - explicit input shape\n",
    "        layers.Input(shape=(32, 32, 3)),\n",
    "\n",
    "        # Your original CNN architecture\n",
    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "\n",
    "        # Enhanced capacity and regularization\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return model"
   ],
   "id": "d1696184f96457af"
  },
  {
   "cell_type": "markdown",
   "id": "8ed49a7a",
   "metadata": {},
   "source": [
    "## Neuronové síť - učení a evaluace\n",
    "---\n",
    "\n",
    "po dokončení učení se modeli uloží do .keras souborů"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "# Create and train the teacher model\n",
    "print(\"Training the teacher model...\")\n",
    "teacher_model = create_teacher_model()\n",
    "teacher_model.summary()\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Model checkpoint callback\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'best_teacher_model.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the teacher model\n",
    "history_teacher = teacher_model.fit(\n",
    "    data_augmentation(training_images),\n",
    "    training_labels_one_hot,\n",
    "    batch_size=64,\n",
    "    epochs=20,\n",
    "    validation_data=(test_images, test_labels_one_hot),\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    ")\n",
    "\n",
    "# Generate teacher's soft predictions\n",
    "print(\"Generating teacher's predictions...\")\n",
    "teacher_predictions = teacher_model.predict(training_images)\n",
    "teacher_test_predictions = teacher_model.predict(test_images)\n",
    "\n",
    "# Create combined labels with ground truth and teacher predictions\n",
    "y_train_combined = np.concatenate([training_labels_one_hot, teacher_predictions], axis=1)\n",
    "y_test_combined = np.concatenate([test_labels_one_hot, teacher_test_predictions], axis=1)\n",
    "\n",
    "# Create and train the student model\n",
    "print(\"Training the student model with knowledge distillation...\")\n",
    "student_model = create_student_model()\n",
    "student_model.summary()\n",
    "\n",
    "# Compile student model with knowledge distillation loss\n",
    "student_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=knowledge_distillation_loss(alpha=0.5, temperature=5.0),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train student model\n",
    "history_student = student_model.fit(\n",
    "    data_augmentation(training_images),\n",
    "    y_train_combined,\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    validation_data=(test_images, y_test_combined),\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ModelCheckpoint('best_student_model.keras',\n",
    "                                           monitor='val_accuracy',\n",
    "                                           save_best_only=True,\n",
    "                                           verbose=1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Recompile student model for evaluation with standard categorical crossentropy\n",
    "student_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Evaluate the student model\n",
    "test_loss, test_accuracy = student_model.evaluate(test_images, test_labels_one_hot)\n",
    "print(f\"Student model test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Train a baseline model without knowledge distillation for comparison\n",
    "print(\"\\nTraining a baseline model without distillation for comparison...\")\n",
    "baseline_model = create_student_model()\n",
    "baseline_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_baseline = baseline_model.fit(\n",
    "    data_augmentation(training_images),\n",
    "    training_labels_one_hot,\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    validation_data=(test_images, test_labels_one_hot),\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ModelCheckpoint('best_baseline_model.keras',\n",
    "                                           monitor='val_accuracy',\n",
    "                                           save_best_only=True,\n",
    "                                           verbose=1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "baseline_loss, baseline_accuracy = baseline_model.evaluate(test_images, test_labels_one_hot)\n",
    "print(f\"Baseline model test accuracy: {baseline_accuracy:.4f}\")\n",
    "print(f\"Student model test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Improvement: {(test_accuracy - baseline_accuracy) * 100:.2f}%\")"
   ],
   "id": "375de4198b418458"
  },
  {
   "cell_type": "markdown",
   "id": "235cd4fc",
   "metadata": {},
   "source": [
    "## Neuronová síť - zobrazení učení\n",
    "---"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_student.history['accuracy'], label='Student Training')\n",
    "plt.plot(history_student.history['val_accuracy'], label='Student Validation')\n",
    "plt.plot(history_baseline.history['accuracy'], label='Baseline Training')\n",
    "plt.plot(history_baseline.history['val_accuracy'], label='Baseline Validation')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_student.history['loss'], label='Student Training')\n",
    "plt.plot(history_student.history['val_loss'], label='Student Validation')\n",
    "plt.plot(history_baseline.history['loss'], label='Baseline Training')\n",
    "plt.plot(history_baseline.history['val_loss'], label='Baseline Validation')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the final models\n",
    "teacher_model.save('teacher_cifar10_model.keras')\n",
    "student_model.save('distilled_cifar10_model.keras')\n",
    "baseline_model.save('baseline_cifar10_model.keras')\n",
    "\n",
    "# Make predictions with the student model\n",
    "predictions = student_model.predict(test_images)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = test_labels.reshape(-1)\n",
    "\n",
    "# Display some predictions\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(test_images[i])\n",
    "\n",
    "    predicted_label = class_names[predicted_classes[i]]\n",
    "    true_label = class_names[true_classes[i]]\n",
    "\n",
    "    if predicted_classes[i] == true_classes[i]:\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(f\"{predicted_label} ({true_label})\", color=color)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "51344de1b8d12950"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Testování\n",
    "---"
   ],
   "id": "19b07db947f6aec8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define class names\n",
    "class_names = ['Airplane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
    "\n",
    "# Define the models to test\n",
    "model_paths = [\n",
    "    './distilled_cifar10_model.keras',  # Student model with knowledge distillation\n",
    "    './baseline_cifar10_model.keras',   # Baseline model without distillation\n",
    "    './teacher_cifar10_model.keras'     # Teacher model\n",
    "]\n",
    "\n",
    "# Path to your test images\n",
    "image_path = \"./images\"\n",
    "\n",
    "# Load image files from the directory\n",
    "image_files = [file for file in os.listdir(image_path) if file.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "# Shuffle image list for randomness\n",
    "random.shuffle(image_files)\n",
    "\n",
    "# Function to test a model\n",
    "def test_model(model_path):\n",
    "    try:\n",
    "        # Load the model\n",
    "        print(f\"\\nLoading model from {model_path}...\")\n",
    "        model = models.load_model(model_path)\n",
    "\n",
    "        # If it's the distilled student model that was saved with custom loss function\n",
    "        # we need to recompile it with standard categorical crossentropy for predictions\n",
    "        if 'distilled' in model_path:\n",
    "            model.compile(\n",
    "                optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "\n",
    "        # Print model summary\n",
    "        model.summary()\n",
    "\n",
    "        count = len(image_files)\n",
    "        success = 0\n",
    "\n",
    "        # Create a figure to display results\n",
    "        plt.figure(figsize=(15, 10))\n",
    "\n",
    "        # Process each image\n",
    "        for i, image_file in enumerate(image_files):\n",
    "            # Extract label from filename\n",
    "            label = image_file.split('.')[0].split('_')[0]\n",
    "\n",
    "            # Load and preprocess the image\n",
    "            image = cv.imread(os.path.join(image_path, image_file))\n",
    "            if image is None:\n",
    "                print(f\"Error loading image {image_file}, skipping...\")\n",
    "                continue\n",
    "\n",
    "            image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "            image = cv.resize(image, (32, 32))\n",
    "\n",
    "            # Display progress\n",
    "            print(\"========================================================\")\n",
    "            print(f\"Calculating prediction for image {image_file} ...\")\n",
    "\n",
    "            # Normalize and make prediction\n",
    "            prediction = model.predict(np.array([image]) / 255, verbose=0)\n",
    "            index = np.argmax(prediction)\n",
    "            predicted_label = class_names[index]\n",
    "\n",
    "            # Check if prediction matches label\n",
    "            is_correct = label.lower() == predicted_label.lower()\n",
    "            if is_correct:\n",
    "                success += 1\n",
    "                color = 'green'\n",
    "            else:\n",
    "                color = 'red'\n",
    "\n",
    "            # Display results\n",
    "            print(f\"Prediction: {predicted_label} (Confidence: {prediction[0][index]:.4f})\")\n",
    "            print(f\"Actual label: {label}\")\n",
    "            print(f\"Correct: {'Yes' if is_correct else 'No'}\")\n",
    "\n",
    "            # Plot the image with prediction (max 16 images)\n",
    "            if i < 16:\n",
    "                plt.subplot(4, 4, i+1)\n",
    "                plt.imshow(image)\n",
    "                plt.title(f\"True: {label}\", fontsize=10)\n",
    "                plt.xlabel(f\"Pred: {predicted_label}\", color=color, fontsize=10)\n",
    "                plt.xticks([])\n",
    "                plt.yticks([])\n",
    "\n",
    "        # Show the figure\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{os.path.basename(model_path)}_results.png\")\n",
    "        plt.show()\n",
    "\n",
    "        # Print final score\n",
    "        print(\"\\n##############################################\")\n",
    "        print(f\"--- RESULTS FOR {os.path.basename(model_path)} ---\")\n",
    "        print(\"##############################################\")\n",
    "        print(f\"Successfully predicted: {success}/{count}\")\n",
    "        print(f\"Unsuccessfully predicted: {count - success}/{count}\")\n",
    "        print(f\"Accuracy: {(success/count)*100.0:.2f}%\")\n",
    "\n",
    "        return (success/count)*100.0\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error testing model {model_path}: {str(e)}\")\n",
    "        return 0.0\n",
    "\n",
    "# Test each model and collect results\n",
    "results = {}\n",
    "for model_path in model_paths:\n",
    "    try:\n",
    "        accuracy = test_model(model_path)\n",
    "        results[os.path.basename(model_path)] = accuracy\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Model file {model_path} not found, skipping...\")\n",
    "\n",
    "# Compare results\n",
    "if results:\n",
    "    print(\"\\n##############################################\")\n",
    "    print(\"------------- COMPARISON RESULTS -------------\")\n",
    "    print(\"##############################################\")\n",
    "    for model_name, accuracy in sorted(results.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{model_name}: {accuracy:.2f}%\")\n",
    "else:\n",
    "    print(\"\\nNo models were successfully tested. Please check the model paths.\")"
   ],
   "id": "33e19c057fa8d24f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Pozorování\n",
    "---\n",
    "Model měl problém s autem značky smart, jelikož příliž připomínal náklaďák (lehce humorné). Dále mu dělalo problém pokud dostal ležícího koně, kterého si zaměňoval se srnkou. Jinak byl docela přesný. Letadala nebyla problém."
   ],
   "id": "b2221a22900bb49c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "89de13f7679cfa09"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
